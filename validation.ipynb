{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakshitrk/handwriten_digit_recogination/blob/master/validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BE7CBuqQqOxZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision as tv\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fI2sFaaVrtLS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "b = 10\n",
        "n_epoch = 50\n",
        "val_split = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukWFwv0-rIKN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = tv.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
        "test_data = tv.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor(),download=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BiaZWrlkstnz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#spliting test data to test and validation data\n",
        "size = len(train_data)\n",
        "indices = list(range(size))\n",
        "split = int(np.floor(val_split * size))\n",
        "np.random.shuffle(indices)\n",
        "train_indices,val_indices = indices[split:],indices[:split]\n",
        "\n",
        "train = SubsetRandomSampler(train_indices)\n",
        "val = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,batch_size=b,sampler=train)\n",
        "val_loader = torch.utils.data.DataLoader(train_data,batch_size=b,sampler=val)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,batch_size=b)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sPxmEeqcvCAz",
        "colab_type": "code",
        "outputId": "bbcd025a-af48-4fae-b5d8-8de9327d2efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "#initalising model\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model,self).__init__()\n",
        "    h1 = 512\n",
        "    h2 = 512\n",
        "    self.l1 = nn.Linear(28*28,h1)\n",
        "    self.l2 = nn.Linear(h1,h2)\n",
        "    self.l3 = nn.Linear(h2,10)\n",
        "    self.drop = nn.Dropout(.2)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    \n",
        "    x = x.view(-1,28*28)\n",
        "    x = F.relu(self.l1(x))\n",
        "    x = self.drop(x)\n",
        "    x = F.relu(self.l2(x))\n",
        "    x = self.drop(x)\n",
        "    x = self.l3(x)\n",
        "    return x\n",
        "    \n",
        "  \n",
        "m = Model()\n",
        "print(m)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (l1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (l2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (l3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (drop): Dropout(p=0.2)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cyLd9Ft0BAwo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "critersion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(m.parameters(),lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgwSL-InDuDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1736
        },
        "outputId": "a8601698-0d4b-4317-911c-c5095e71aa55"
      },
      "cell_type": "code",
      "source": [
        "#training model\n",
        "val_loss_min=np.Inf\n",
        "for epoch in range(n_epoch):\n",
        "  train_loss = 0.0\n",
        "  val_loss = 0.0\n",
        "  \n",
        "  m.train()\n",
        "  for data,target in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    output = m(data)\n",
        "    loss = critersion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()*data.size(0)\n",
        "    \n",
        "  m.eval()\n",
        "  for data,target in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      output = m(data)\n",
        "      loss = critersion(output,target)\n",
        "      val_loss += loss.item()*data.size(0)\n",
        "      \n",
        "  train_loss = train_loss/len(train_loader.dataset)\n",
        "  val_loss = val_loss/len(val_loader.dataset)\n",
        "  \n",
        "  print('Epoch:{} \\ttraining loss:{:.6f} \\tvalidation loss:{:.6f}'\n",
        "        .format(epoch+1,train_loss,val_loss))\n",
        "  \n",
        "  \n",
        "  if val_loss <= val_loss_min:\n",
        "    print('Validation loss dec:{:.6f}-->{:.6f}\\t.....SAVING.........'\n",
        "          .format(val_loss_min,val_loss))\n",
        "    \n",
        "    torch.save(m.state_dict(),'m.pt')\n",
        "    val_loss_min = val_loss\n",
        "    \n",
        "  \n",
        "      \n",
        "    \n",
        "    \n",
        "  "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1 \ttraining loss:0.528340 \tvalidation loss:0.232492\n",
            "Validation loss dec:inf-->0.232492\t.....SAVING.........\n",
            "Epoch:2 \ttraining loss:0.210947 \tvalidation loss:0.153556\n",
            "Validation loss dec:0.232492-->0.153556\t.....SAVING.........\n",
            "Epoch:3 \ttraining loss:0.152601 \tvalidation loss:0.112726\n",
            "Validation loss dec:0.153556-->0.112726\t.....SAVING.........\n",
            "Epoch:4 \ttraining loss:0.119117 \tvalidation loss:0.087895\n",
            "Validation loss dec:0.112726-->0.087895\t.....SAVING.........\n",
            "Epoch:5 \ttraining loss:0.097320 \tvalidation loss:0.070449\n",
            "Validation loss dec:0.087895-->0.070449\t.....SAVING.........\n",
            "Epoch:6 \ttraining loss:0.083265 \tvalidation loss:0.060774\n",
            "Validation loss dec:0.070449-->0.060774\t.....SAVING.........\n",
            "Epoch:7 \ttraining loss:0.071515 \tvalidation loss:0.051969\n",
            "Validation loss dec:0.060774-->0.051969\t.....SAVING.........\n",
            "Epoch:8 \ttraining loss:0.062331 \tvalidation loss:0.042162\n",
            "Validation loss dec:0.051969-->0.042162\t.....SAVING.........\n",
            "Epoch:9 \ttraining loss:0.054372 \tvalidation loss:0.036368\n",
            "Validation loss dec:0.042162-->0.036368\t.....SAVING.........\n",
            "Epoch:10 \ttraining loss:0.049014 \tvalidation loss:0.031063\n",
            "Validation loss dec:0.036368-->0.031063\t.....SAVING.........\n",
            "Epoch:11 \ttraining loss:0.043910 \tvalidation loss:0.026635\n",
            "Validation loss dec:0.031063-->0.026635\t.....SAVING.........\n",
            "Epoch:12 \ttraining loss:0.038201 \tvalidation loss:0.024424\n",
            "Validation loss dec:0.026635-->0.024424\t.....SAVING.........\n",
            "Epoch:13 \ttraining loss:0.035267 \tvalidation loss:0.020390\n",
            "Validation loss dec:0.024424-->0.020390\t.....SAVING.........\n",
            "Epoch:14 \ttraining loss:0.031449 \tvalidation loss:0.017199\n",
            "Validation loss dec:0.020390-->0.017199\t.....SAVING.........\n",
            "Epoch:15 \ttraining loss:0.028468 \tvalidation loss:0.015157\n",
            "Validation loss dec:0.017199-->0.015157\t.....SAVING.........\n",
            "Epoch:16 \ttraining loss:0.026008 \tvalidation loss:0.012665\n",
            "Validation loss dec:0.015157-->0.012665\t.....SAVING.........\n",
            "Epoch:17 \ttraining loss:0.024442 \tvalidation loss:0.011540\n",
            "Validation loss dec:0.012665-->0.011540\t.....SAVING.........\n",
            "Epoch:18 \ttraining loss:0.020840 \tvalidation loss:0.011489\n",
            "Validation loss dec:0.011540-->0.011489\t.....SAVING.........\n",
            "Epoch:19 \ttraining loss:0.020964 \tvalidation loss:0.009564\n",
            "Validation loss dec:0.011489-->0.009564\t.....SAVING.........\n",
            "Epoch:20 \ttraining loss:0.018010 \tvalidation loss:0.008141\n",
            "Validation loss dec:0.009564-->0.008141\t.....SAVING.........\n",
            "Epoch:21 \ttraining loss:0.016519 \tvalidation loss:0.006945\n",
            "Validation loss dec:0.008141-->0.006945\t.....SAVING.........\n",
            "Epoch:22 \ttraining loss:0.015927 \tvalidation loss:0.006405\n",
            "Validation loss dec:0.006945-->0.006405\t.....SAVING.........\n",
            "Epoch:23 \ttraining loss:0.014972 \tvalidation loss:0.005885\n",
            "Validation loss dec:0.006405-->0.005885\t.....SAVING.........\n",
            "Epoch:24 \ttraining loss:0.013614 \tvalidation loss:0.004753\n",
            "Validation loss dec:0.005885-->0.004753\t.....SAVING.........\n",
            "Epoch:25 \ttraining loss:0.012196 \tvalidation loss:0.004373\n",
            "Validation loss dec:0.004753-->0.004373\t.....SAVING.........\n",
            "Epoch:26 \ttraining loss:0.011482 \tvalidation loss:0.004154\n",
            "Validation loss dec:0.004373-->0.004154\t.....SAVING.........\n",
            "Epoch:27 \ttraining loss:0.011732 \tvalidation loss:0.003910\n",
            "Validation loss dec:0.004154-->0.003910\t.....SAVING.........\n",
            "Epoch:28 \ttraining loss:0.010101 \tvalidation loss:0.003001\n",
            "Validation loss dec:0.003910-->0.003001\t.....SAVING.........\n",
            "Epoch:29 \ttraining loss:0.009507 \tvalidation loss:0.003144\n",
            "Epoch:30 \ttraining loss:0.009412 \tvalidation loss:0.002776\n",
            "Validation loss dec:0.003001-->0.002776\t.....SAVING.........\n",
            "Epoch:31 \ttraining loss:0.008484 \tvalidation loss:0.002542\n",
            "Validation loss dec:0.002776-->0.002542\t.....SAVING.........\n",
            "Epoch:32 \ttraining loss:0.008567 \tvalidation loss:0.002377\n",
            "Validation loss dec:0.002542-->0.002377\t.....SAVING.........\n",
            "Epoch:33 \ttraining loss:0.007580 \tvalidation loss:0.002747\n",
            "Epoch:34 \ttraining loss:0.007436 \tvalidation loss:0.002008\n",
            "Validation loss dec:0.002377-->0.002008\t.....SAVING.........\n",
            "Epoch:35 \ttraining loss:0.006601 \tvalidation loss:0.001610\n",
            "Validation loss dec:0.002008-->0.001610\t.....SAVING.........\n",
            "Epoch:36 \ttraining loss:0.006542 \tvalidation loss:0.001737\n",
            "Epoch:37 \ttraining loss:0.006263 \tvalidation loss:0.001626\n",
            "Epoch:38 \ttraining loss:0.006236 \tvalidation loss:0.001383\n",
            "Validation loss dec:0.001610-->0.001383\t.....SAVING.........\n",
            "Epoch:39 \ttraining loss:0.006380 \tvalidation loss:0.001440\n",
            "Epoch:40 \ttraining loss:0.005608 \tvalidation loss:0.001423\n",
            "Epoch:41 \ttraining loss:0.005568 \tvalidation loss:0.001302\n",
            "Validation loss dec:0.001383-->0.001302\t.....SAVING.........\n",
            "Epoch:42 \ttraining loss:0.004895 \tvalidation loss:0.001030\n",
            "Validation loss dec:0.001302-->0.001030\t.....SAVING.........\n",
            "Epoch:43 \ttraining loss:0.004642 \tvalidation loss:0.000996\n",
            "Validation loss dec:0.001030-->0.000996\t.....SAVING.........\n",
            "Epoch:44 \ttraining loss:0.004857 \tvalidation loss:0.001019\n",
            "Epoch:45 \ttraining loss:0.004899 \tvalidation loss:0.000927\n",
            "Validation loss dec:0.000996-->0.000927\t.....SAVING.........\n",
            "Epoch:46 \ttraining loss:0.004599 \tvalidation loss:0.000778\n",
            "Validation loss dec:0.000927-->0.000778\t.....SAVING.........\n",
            "Epoch:47 \ttraining loss:0.003971 \tvalidation loss:0.000717\n",
            "Validation loss dec:0.000778-->0.000717\t.....SAVING.........\n",
            "Epoch:48 \ttraining loss:0.003574 \tvalidation loss:0.000646\n",
            "Validation loss dec:0.000717-->0.000646\t.....SAVING.........\n",
            "Epoch:49 \ttraining loss:0.003985 \tvalidation loss:0.000833\n",
            "Epoch:50 \ttraining loss:0.004059 \tvalidation loss:0.000602\n",
            "Validation loss dec:0.000646-->0.000602\t.....SAVING.........\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qon11vSMwxa-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m.load_state_dict(torch.load('m.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S3Li3AtfETTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for data,target in test_loader:\n",
        "  output = m(data)\n",
        "  _, pred = torch.max(output,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itOKRPyYsWqN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "13d4b17b-3cdc-47dd-d25e-ad8bec2512f3"
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for data in test_loader:\n",
        "  images,labels = data\n",
        "  output = m(images)\n",
        "  _, pred = torch.max(output,1)\n",
        "  \n",
        "  total += labels.size(0)\n",
        "  correct += (pred == labels).sum().item()\n",
        "  \n",
        "  acc = 100*correct/total\n",
        "print('Accuracy of model:{}%'.format(acc))\n",
        "  "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model:98.28%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}